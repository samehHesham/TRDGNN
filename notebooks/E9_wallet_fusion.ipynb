{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E9: Wallet Fusion - GNN Embeddings + Tabular Features\n",
    "\n",
    "**Goal:** Combine E7-A3 GNN embeddings with tabular features using XGBoost fusion\n",
    "\n",
    "**Hypothesis:** GNN (relational) + Tabular (statistical) > Either alone\n",
    "\n",
    "**Date:** November 11, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_curve, auc, roc_auc_score, \n",
    "    f1_score, roc_curve\n",
    ")\n",
    "import xgboost as xgb\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Extract E7-A3 Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load heterogeneous graph\n",
    "hetero_data = torch.load('/kaggle/input/elliptic-hetero-graph/hetero_graph.pt')\n",
    "\n",
    "print(\"Heterogeneous graph loaded:\")\n",
    "print(f\"  Transactions: {hetero_data['transaction'].x.shape[0]}\")\n",
    "print(f\"  Addresses: {hetero_data['address'].x.shape[0]}\")\n",
    "print(f\"  Edge types: {len(hetero_data.edge_types)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Simple-HHGTN model (from E7-A3)\n",
    "from torch_geometric.nn import HeteroConv, SAGEConv\n",
    "\n",
    "class SimpleHHGTN(nn.Module):\n",
    "    def __init__(self, hidden_dim=128, num_layers=2, dropout=0.4):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Input projections\n",
    "        self.tx_proj = nn.Linear(93, hidden_dim)\n",
    "        self.addr_proj = nn.Linear(55, hidden_dim)\n",
    "        \n",
    "        # HeteroConv layers\n",
    "        self.convs = nn.ModuleList([\n",
    "            HeteroConv({\n",
    "                ('transaction', 'tx_to_tx', 'transaction'): SAGEConv(-1, hidden_dim),\n",
    "                ('address', 'addr_to_tx', 'transaction'): SAGEConv(-1, hidden_dim),\n",
    "                ('transaction', 'tx_to_addr', 'address'): SAGEConv(-1, hidden_dim),\n",
    "                ('address', 'addr_to_addr', 'address'): SAGEConv(-1, hidden_dim),\n",
    "            }, aggr='sum')\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, 2)\n",
    "        )\n",
    "    \n",
    "    def get_embeddings(self, x_dict, edge_index_dict):\n",
    "        \"\"\"Extract embeddings before classification\"\"\"\n",
    "        # Project inputs\n",
    "        x_dict = {\n",
    "            'transaction': self.tx_proj(x_dict['transaction']),\n",
    "            'address': self.addr_proj(x_dict['address'])\n",
    "        }\n",
    "        \n",
    "        # Message passing\n",
    "        for conv in self.convs:\n",
    "            x_dict = conv(x_dict, edge_index_dict)\n",
    "            x_dict = {key: F.dropout(F.relu(x), p=self.dropout, training=False) \n",
    "                     for key, x in x_dict.items()}\n",
    "        \n",
    "        return x_dict\n",
    "    \n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        # Get embeddings\n",
    "        embeddings = self.get_embeddings(x_dict, edge_index_dict)\n",
    "        \n",
    "        # Classify transactions only\n",
    "        return self.classifier(embeddings['transaction'])\n",
    "\n",
    "print(\"Model architecture defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained E7-A3 checkpoint\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize model\n",
    "model = SimpleHHGTN(hidden_dim=128, num_layers=2, dropout=0.4)\n",
    "model.to(device)\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load('/kaggle/input/e7-a3-checkpoint/a3_best.pt', map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "print(f\"E7-A3 model loaded (best epoch: {checkpoint.get('epoch', 'N/A')})\")\n",
    "print(f\"Best val PR-AUC: {checkpoint.get('best_val_pr_auc', 'N/A'):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embeddings\n",
    "print(\"Extracting embeddings from E7-A3 model...\")\n",
    "\n",
    "hetero_data = hetero_data.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    embeddings = model.get_embeddings(\n",
    "        hetero_data.x_dict,\n",
    "        hetero_data.edge_index_dict\n",
    "    )\n",
    "    \n",
    "    # Move to CPU and convert to numpy\n",
    "    tx_embeddings = embeddings['transaction'].cpu().numpy()\n",
    "    addr_embeddings = embeddings['address'].cpu().numpy()\n",
    "\n",
    "print(f\"Transaction embeddings: {tx_embeddings.shape}\")  # [203769, 128]\n",
    "print(f\"Address embeddings: {addr_embeddings.shape}\")      # [100000, 128]\n",
    "\n",
    "# Save embeddings\n",
    "np.save('e9_tx_embeddings.npy', tx_embeddings)\n",
    "np.save('e9_addr_embeddings.npy', addr_embeddings)\n",
    "print(\"Embeddings saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Tabular Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load transaction features (AF1-AF93)\n",
    "tx_features_df = pd.read_csv('/kaggle/input/elliptic-plus-plus/txs_features.csv')\n",
    "\n",
    "# Extract local features only (columns 2-94: Time step + AF1-AF93)\n",
    "# Skip Time step (column 1), use AF1-AF93 (columns 2-94)\n",
    "tx_features = tx_features_df.iloc[:, 2:95].values\n",
    "\n",
    "print(f\"Transaction features loaded: {tx_features.shape}\")  # [203769, 93]\n",
    "print(f\"Feature range: [{tx_features.min():.2f}, {tx_features.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load labels and splits\n",
    "labels_df = pd.read_csv('/kaggle/input/elliptic-plus-plus/txs_classes.csv')\n",
    "with open('/kaggle/input/elliptic-splits/splits.json') as f:\n",
    "    splits = json.load(f)\n",
    "\n",
    "# Convert labels to binary (1=fraud, 2=licit → 1=fraud, 0=licit)\n",
    "labels = labels_df['class'].values\n",
    "y = (labels == 1).astype(int)\n",
    "\n",
    "# Get split masks\n",
    "train_mask = np.array(splits['train'])\n",
    "val_mask = np.array(splits['val'])\n",
    "test_mask = np.array(splits['test'])\n",
    "\n",
    "print(f\"Labels: Fraud={(y==1).sum()}, Licit={(y==0).sum()}, Unknown={(labels==3).sum()}\")\n",
    "print(f\"Splits: Train={train_mask.sum()}, Val={val_mask.sum()}, Test={test_mask.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create Fusion Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize tabular features (fit on train, transform all)\n",
    "scaler = StandardScaler()\n",
    "tx_features_norm = scaler.fit_transform(tx_features[train_mask])\n",
    "tx_features_norm_all = scaler.transform(tx_features)\n",
    "\n",
    "print(f\"Normalized features: {tx_features_norm_all.shape}\")\n",
    "print(f\"  Mean: {tx_features_norm_all[train_mask].mean():.4f}\")\n",
    "print(f\"  Std: {tx_features_norm_all[train_mask].std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fusion features (embeddings + tabular)\n",
    "tx_fusion = np.concatenate([tx_embeddings, tx_features_norm_all], axis=1)\n",
    "\n",
    "print(f\"Fusion features created: {tx_fusion.shape}\")  # [203769, 128+93=221]\n",
    "print(f\"  Embeddings: 128 dims\")\n",
    "print(f\"  Tabular: 93 dims\")\n",
    "print(f\"  Total: 221 dims\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train Three XGBoost Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class weight\n",
    "pos_weight = (y[train_mask] == 0).sum() / (y[train_mask] == 1).sum()\n",
    "print(f\"Class weight (pos_weight): {pos_weight:.2f}\")\n",
    "\n",
    "# XGBoost parameters\n",
    "xgb_params = {\n",
    "    'max_depth': 6,\n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': 100,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'scale_pos_weight': pos_weight,\n",
    "    'random_state': 42,\n",
    "    'tree_method': 'hist',\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "}\n",
    "\n",
    "print(f\"XGBoost device: {xgb_params['device']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: Tabular Only\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training Model 1: Tabular Only (AF1-AF93)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model_tabular = xgb.XGBClassifier(**xgb_params)\n",
    "model_tabular.fit(\n",
    "    tx_features_norm_all[train_mask], \n",
    "    y[train_mask],\n",
    "    eval_set=[(tx_features_norm_all[val_mask], y[val_mask])],\n",
    "    verbose=10\n",
    ")\n",
    "\n",
    "pred_tabular = model_tabular.predict_proba(tx_features_norm_all[test_mask])[:, 1]\n",
    "print(f\"\\nTabular model trained. Test predictions range: [{pred_tabular.min():.4f}, {pred_tabular.max():.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: Embeddings Only\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training Model 2: Embeddings Only (GNN 128-dim)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model_embeddings = xgb.XGBClassifier(**xgb_params)\n",
    "model_embeddings.fit(\n",
    "    tx_embeddings[train_mask], \n",
    "    y[train_mask],\n",
    "    eval_set=[(tx_embeddings[val_mask], y[val_mask])],\n",
    "    verbose=10\n",
    ")\n",
    "\n",
    "pred_embeddings = model_embeddings.predict_proba(tx_embeddings[test_mask])[:, 1]\n",
    "print(f\"\\nEmbeddings model trained. Test predictions range: [{pred_embeddings.min():.4f}, {pred_embeddings.max():.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3: Fusion\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training Model 3: Fusion (Embeddings + Tabular, 221-dim)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model_fusion = xgb.XGBClassifier(**xgb_params)\n",
    "model_fusion.fit(\n",
    "    tx_fusion[train_mask], \n",
    "    y[train_mask],\n",
    "    eval_set=[(tx_fusion[val_mask], y[val_mask])],\n",
    "    verbose=10\n",
    ")\n",
    "\n",
    "pred_fusion = model_fusion.predict_proba(tx_fusion[test_mask])[:, 1]\n",
    "print(f\"\\nFusion model trained. Test predictions range: [{pred_fusion.min():.4f}, {pred_fusion.max():.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate & Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_pred_proba):\n",
    "    \"\"\"Compute PR-AUC, ROC-AUC, F1\"\"\"\n",
    "    # PR-AUC\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_pred_proba)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    \n",
    "    # ROC-AUC\n",
    "    roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
    "    \n",
    "    # F1 at optimal threshold\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred_proba)\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    y_pred_binary = (y_pred_proba >= optimal_threshold).astype(int)\n",
    "    f1 = f1_score(y_true, y_pred_binary)\n",
    "    \n",
    "    return {\n",
    "        'pr_auc': float(pr_auc),\n",
    "        'roc_auc': float(roc_auc),\n",
    "        'f1': float(f1),\n",
    "        'threshold': float(optimal_threshold)\n",
    "    }\n",
    "\n",
    "# Compute metrics for all three models\n",
    "y_test = y[test_mask]\n",
    "\n",
    "results = {\n",
    "    'tabular_only': compute_metrics(y_test, pred_tabular),\n",
    "    'embeddings_only': compute_metrics(y_test, pred_embeddings),\n",
    "    'fusion': compute_metrics(y_test, pred_fusion)\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"E9 WALLET FUSION RESULTS (Transaction-Level Fraud Detection)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"\\n{model_name.upper().replace('_', ' ')}:\")\n",
    "    print(f\"  PR-AUC:   {metrics['pr_auc']:.4f}\")\n",
    "    print(f\"  ROC-AUC:  {metrics['roc_auc']:.4f}\")\n",
    "    print(f\"  F1:       {metrics['f1']:.4f}\")\n",
    "\n",
    "# Calculate improvements\n",
    "fusion_vs_tabular = (results['fusion']['pr_auc'] - results['tabular_only']['pr_auc']) / results['tabular_only']['pr_auc'] * 100\n",
    "fusion_vs_embeddings = (results['fusion']['pr_auc'] - results['embeddings_only']['pr_auc']) / results['embeddings_only']['pr_auc'] * 100\n",
    "\n",
    "print(f\"\\n{'-'*70}\")\n",
    "print(f\"FUSION IMPROVEMENT:\")\n",
    "print(f\"  vs Tabular Only:    {fusion_vs_tabular:+.1f}%\")\n",
    "print(f\"  vs Embeddings Only: {fusion_vs_embeddings:+.1f}%\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "with open('e9_fusion_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"Results saved to e9_fusion_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison bar chart\n",
    "sns.set_style('whitegrid')\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "models = ['Tabular\\nOnly', 'Embeddings\\nOnly', 'Fusion']\n",
    "metrics_names = ['PR-AUC', 'ROC-AUC', 'F1']\n",
    "colors = ['#3498db', '#e74c3c', '#2ecc71']\n",
    "\n",
    "for idx, metric_key in enumerate(['pr_auc', 'roc_auc', 'f1']):\n",
    "    values = [\n",
    "        results['tabular_only'][metric_key],\n",
    "        results['embeddings_only'][metric_key],\n",
    "        results['fusion'][metric_key]\n",
    "    ]\n",
    "    \n",
    "    bars = axes[idx].bar(models, values, color=colors)\n",
    "    axes[idx].set_ylabel(metrics_names[idx], fontsize=12)\n",
    "    axes[idx].set_ylim([0, 1])\n",
    "    axes[idx].set_title(f'{metrics_names[idx]} Comparison', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, val in zip(bars, values):\n",
    "        height = bar.get_height()\n",
    "        axes[idx].text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "                      f'{val:.4f}', ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    # Highlight best\n",
    "    best_idx = np.argmax(values)\n",
    "    bars[best_idx].set_edgecolor('gold')\n",
    "    bars[best_idx].set_linewidth(3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('e9_fusion_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Comparison chart saved: e9_fusion_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PR and ROC curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# PR Curves\n",
    "for name, pred, color, label in [\n",
    "    ('tabular', pred_tabular, '#3498db', 'Tabular Only'),\n",
    "    ('embeddings', pred_embeddings, '#e74c3c', 'Embeddings Only'),\n",
    "    ('fusion', pred_fusion, '#2ecc71', 'Fusion')\n",
    "]:\n",
    "    precision, recall, _ = precision_recall_curve(y_test, pred)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    axes[0].plot(recall, precision, color=color, lw=2.5, \n",
    "                label=f'{label} (PR-AUC={pr_auc:.4f})')\n",
    "\n",
    "axes[0].set_xlabel('Recall', fontsize=12)\n",
    "axes[0].set_ylabel('Precision', fontsize=12)\n",
    "axes[0].set_title('Precision-Recall Curves', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(loc='best', fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# ROC Curves\n",
    "for name, pred, color, label in [\n",
    "    ('tabular', pred_tabular, '#3498db', 'Tabular Only'),\n",
    "    ('embeddings', pred_embeddings, '#e74c3c', 'Embeddings Only'),\n",
    "    ('fusion', pred_fusion, '#2ecc71', 'Fusion')\n",
    "]:\n",
    "    fpr, tpr, _ = roc_curve(y_test, pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    axes[1].plot(fpr, tpr, color=color, lw=2.5, \n",
    "                label=f'{label} (ROC-AUC={roc_auc:.4f})')\n",
    "\n",
    "axes[1].plot([0, 1], [0, 1], 'k--', lw=1, alpha=0.3)\n",
    "axes[1].set_xlabel('False Positive Rate', fontsize=12)\n",
    "axes[1].set_ylabel('True Positive Rate', fontsize=12)\n",
    "axes[1].set_title('ROC Curves', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(loc='best', fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('e9_fusion_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"PR/ROC curves saved: e9_fusion_curves.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"E9 WALLET FUSION EXPERIMENT COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nDeliverables created:\")\n",
    "print(\"  ✅ e9_tx_embeddings.npy - Transaction embeddings [203769, 128]\")\n",
    "print(\"  ✅ e9_addr_embeddings.npy - Address embeddings [100000, 128]\")\n",
    "print(\"  ✅ e9_fusion_results.json - All metrics\")\n",
    "print(\"  ✅ e9_fusion_comparison.png - Bar chart comparison\")\n",
    "print(\"  ✅ e9_fusion_curves.png - PR/ROC curves\")\n",
    "print(\"\\nKey Finding:\")\n",
    "if results['fusion']['pr_auc'] > max(results['tabular_only']['pr_auc'], results['embeddings_only']['pr_auc']):\n",
    "    print(\"  ⭐ FUSION WINS: GNN embeddings + tabular features > either alone\")\n",
    "    print(f\"  ⭐ Best PR-AUC: {results['fusion']['pr_auc']:.4f}\")\n",
    "else:\n",
    "    best_model = max(results, key=lambda k: results[k]['pr_auc'])\n",
    "    print(f\"  ⭐ {best_model.upper()} WINS: {results[best_model]['pr_auc']:.4f} PR-AUC\")\n",
    "\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"  1. Update COMPARISON_REPORT.md with E9 results\")\n",
    "print(\"  2. Update README.md with fusion findings\")\n",
    "print(\"  3. Create E9_WALLET_FUSION_DOCUMENTATION.md\")\n",
    "print(\"  4. Commit to GitHub\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
