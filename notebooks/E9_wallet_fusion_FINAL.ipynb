{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E9: Wallet Fusion - GNN Embeddings + Tabular Features\n",
    "\n",
    "**Goal:** Combine E7-A3 GNN embeddings with tabular features using XGBoost fusion\n",
    "\n",
    "**Date:** November 11, 2025\n",
    "\n",
    "**TESTED & ERROR-FREE VERSION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Install Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PyTorch Geometric (optimized for Kaggle)\n",
    "import sys\n",
    "print(\"Installing PyTorch Geometric (this takes 3-5 minutes on Kaggle)...\")\n",
    "!pip install -q pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.1.0+cu121.html\n",
    "!pip install -q torch-geometric\n",
    "print(\"✓ PyTorch Geometric installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_recall_curve, auc, roc_auc_score, f1_score, roc_curve\n",
    "import xgboost as xgb\n",
    "from torch_geometric.nn import HeteroConv, SAGEConv\n",
    "\n",
    "# Set seeds\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"✓ Libraries imported\")\n",
    "print(f\"✓ Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load heterogeneous graph\n",
    "print(\"Loading heterogeneous graph...\")\n",
    "hetero_data = torch.load('/kaggle/input/a3-dataset/hetero_graph.pt', weights_only=False)\n",
    "\n",
    "print(f\"✓ Graph loaded:\")\n",
    "print(f\"  Transactions: {hetero_data['transaction'].x.shape[0]}\")\n",
    "print(f\"  Addresses: {hetero_data['address'].x.shape[0]}\")\n",
    "print(f\"  Edge types: {len(hetero_data.edge_types)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load labels and splits\n",
    "print(\"Loading labels and splits...\")\n",
    "\n",
    "labels_df = pd.read_csv('/kaggle/input/elliptic-plus-plus/txs_classes.csv')\n",
    "with open('/kaggle/input/elliptic-splits/splits.json') as f:\n",
    "    splits = json.load(f)\n",
    "\n",
    "# Convert to binary\n",
    "labels = labels_df['class'].values\n",
    "y = (labels == 1).astype(int)\n",
    "\n",
    "# Create masks\n",
    "train_mask = np.array(splits['train'])\n",
    "val_mask = np.array(splits['val'])\n",
    "test_mask = np.array(splits['test'])\n",
    "\n",
    "print(f\"✓ Labels loaded:\")\n",
    "print(f\"  Fraud: {(y==1).sum()}, Licit: {(y==0).sum()}\")\n",
    "print(f\"  Train: {train_mask.sum()}, Val: {val_mask.sum()}, Test: {test_mask.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load transaction features (AF1-AF93)\n",
    "print(\"Loading transaction features...\")\n",
    "\n",
    "tx_features_df = pd.read_csv('/kaggle/input/elliptic-plus-plus/txs_features.csv')\n",
    "tx_features = tx_features_df.iloc[:, 2:95].values  # AF1-AF93\n",
    "\n",
    "print(f\"✓ Features loaded: {tx_features.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define Model Architecture (Matching Checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define EXACT model from E7-A3 checkpoint\n",
    "class E7_A3_Model(nn.Module):\n",
    "    def __init__(self, hidden_dim=128, dropout=0.4):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Input projections (ModuleDict)\n",
    "        self.input_projs = nn.ModuleDict({\n",
    "            'transaction': nn.Linear(93, hidden_dim),\n",
    "            'address': nn.Linear(55, hidden_dim)\n",
    "        })\n",
    "        \n",
    "        # Single HeteroConv layer\n",
    "        self.convs = HeteroConv({\n",
    "            ('transaction', 'transaction__to__transaction', 'transaction'): SAGEConv(hidden_dim, hidden_dim),\n",
    "            ('address', 'address__to__transaction', 'transaction'): SAGEConv(hidden_dim, hidden_dim),\n",
    "            ('transaction', 'transaction__to__address', 'address'): SAGEConv(hidden_dim, hidden_dim),\n",
    "            ('address', 'address__to__address', 'address'): SAGEConv(hidden_dim, hidden_dim),\n",
    "        }, aggr='sum')\n",
    "        \n",
    "        # Attention layer\n",
    "        self.attn = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "        # Classifier (single linear layer)\n",
    "        self.classifier = nn.Linear(hidden_dim, 2)\n",
    "        \n",
    "        self.dropout = dropout\n",
    "    \n",
    "    def get_embeddings(self, x_dict, edge_index_dict):\n",
    "        \"\"\"Extract embeddings before classification\"\"\"\n",
    "        # Project inputs\n",
    "        x_dict = {key: self.input_projs[key](x) for key, x in x_dict.items()}\n",
    "        \n",
    "        # Message passing\n",
    "        x_dict = self.convs(x_dict, edge_index_dict)\n",
    "        x_dict = {key: F.dropout(F.relu(x), p=self.dropout, training=False) \n",
    "                 for key, x in x_dict.items()}\n",
    "        \n",
    "        return x_dict\n",
    "    \n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        embeddings = self.get_embeddings(x_dict, edge_index_dict)\n",
    "        return self.classifier(embeddings['transaction'])\n",
    "\n",
    "print(\"✓ Model architecture defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading E7-A3 checkpoint...\")\n",
    "\n",
    "# Initialize model\n",
    "model = E7_A3_Model(hidden_dim=128, dropout=0.4)\n",
    "model.to(device)\n",
    "\n",
    "# Load checkpoint (state_dict directly)\n",
    "checkpoint = torch.load('/kaggle/input/a3-dataset/a3_best.pt', map_location=device, weights_only=False)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()\n",
    "\n",
    "print(\"✓ Model loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Extract Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Extracting embeddings from E7-A3 model...\")\n",
    "\n",
    "hetero_data = hetero_data.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    embeddings = model.get_embeddings(\n",
    "        hetero_data.x_dict,\n",
    "        hetero_data.edge_index_dict\n",
    "    )\n",
    "    \n",
    "    # Move to CPU\n",
    "    tx_embeddings = embeddings['transaction'].cpu().numpy()\n",
    "    addr_embeddings = embeddings['address'].cpu().numpy()\n",
    "\n",
    "print(f\"✓ Embeddings extracted:\")\n",
    "print(f\"  Transaction: {tx_embeddings.shape}\")\n",
    "print(f\"  Address: {addr_embeddings.shape}\")\n",
    "\n",
    "# Save\n",
    "np.save('e9_tx_embeddings.npy', tx_embeddings)\n",
    "np.save('e9_addr_embeddings.npy', addr_embeddings)\n",
    "print(\"✓ Embeddings saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Create Fusion Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating fusion features...\")\n",
    "\n",
    "# Normalize tabular features (fit on train, transform all)\n",
    "scaler = StandardScaler()\n",
    "tx_features_norm = scaler.fit_transform(tx_features[train_mask])\n",
    "tx_features_norm_all = scaler.transform(tx_features)\n",
    "\n",
    "# Create fusion features\n",
    "tx_fusion = np.concatenate([tx_embeddings, tx_features_norm_all], axis=1)\n",
    "\n",
    "print(f\"✓ Fusion features created: {tx_fusion.shape}\")\n",
    "print(f\"  Embeddings (128) + Tabular (93) = 221 dims\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Train Three XGBoost Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class weight\n",
    "pos_weight = (y[train_mask] == 0).sum() / (y[train_mask] == 1).sum()\n",
    "\n",
    "# XGBoost parameters\n",
    "xgb_params = {\n",
    "    'max_depth': 6,\n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': 100,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'scale_pos_weight': pos_weight,\n",
    "    'random_state': 42,\n",
    "    'tree_method': 'hist',\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "}\n",
    "\n",
    "print(f\"✓ XGBoost params configured (device: {xgb_params['device']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: Tabular Only\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training Model 1: Tabular Only (AF1-AF93)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model_tabular = xgb.XGBClassifier(**xgb_params)\n",
    "model_tabular.fit(\n",
    "    tx_features_norm_all[train_mask], \n",
    "    y[train_mask],\n",
    "    eval_set=[(tx_features_norm_all[val_mask], y[val_mask])],\n",
    "    verbose=10\n",
    ")\n",
    "\n",
    "pred_tabular = model_tabular.predict_proba(tx_features_norm_all[test_mask])[:, 1]\n",
    "print(f\"\\n✓ Tabular model trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: Embeddings Only\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training Model 2: Embeddings Only (GNN 128-dim)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model_embeddings = xgb.XGBClassifier(**xgb_params)\n",
    "model_embeddings.fit(\n",
    "    tx_embeddings[train_mask], \n",
    "    y[train_mask],\n",
    "    eval_set=[(tx_embeddings[val_mask], y[val_mask])],\n",
    "    verbose=10\n",
    ")\n",
    "\n",
    "pred_embeddings = model_embeddings.predict_proba(tx_embeddings[test_mask])[:, 1]\n",
    "print(f\"\\n✓ Embeddings model trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3: Fusion\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training Model 3: Fusion (221-dim)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model_fusion = xgb.XGBClassifier(**xgb_params)\n",
    "model_fusion.fit(\n",
    "    tx_fusion[train_mask], \n",
    "    y[train_mask],\n",
    "    eval_set=[(tx_fusion[val_mask], y[val_mask])],\n",
    "    verbose=10\n",
    ")\n",
    "\n",
    "pred_fusion = model_fusion.predict_proba(tx_fusion[test_mask])[:, 1]\n",
    "print(f\"\\n✓ Fusion model trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Evaluate & Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_pred_proba):\n",
    "    \"\"\"Compute PR-AUC, ROC-AUC, F1\"\"\"\n",
    "    # PR-AUC\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_pred_proba)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    \n",
    "    # ROC-AUC\n",
    "    roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
    "    \n",
    "    # F1\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred_proba)\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    y_pred_binary = (y_pred_proba >= optimal_threshold).astype(int)\n",
    "    f1 = f1_score(y_true, y_pred_binary)\n",
    "    \n",
    "    return {\n",
    "        'pr_auc': float(pr_auc),\n",
    "        'roc_auc': float(roc_auc),\n",
    "        'f1': float(f1),\n",
    "        'threshold': float(optimal_threshold)\n",
    "    }\n",
    "\n",
    "# Compute metrics\n",
    "y_test = y[test_mask]\n",
    "\n",
    "results = {\n",
    "    'tabular_only': compute_metrics(y_test, pred_tabular),\n",
    "    'embeddings_only': compute_metrics(y_test, pred_embeddings),\n",
    "    'fusion': compute_metrics(y_test, pred_fusion)\n",
    "}\n",
    "\n",
    "# Print results\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"E9 WALLET FUSION RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"\\n{model_name.upper().replace('_', ' ')}:\")\n",
    "    print(f\"  PR-AUC:   {metrics['pr_auc']:.4f}\")\n",
    "    print(f\"  ROC-AUC:  {metrics['roc_auc']:.4f}\")\n",
    "    print(f\"  F1:       {metrics['f1']:.4f}\")\n",
    "\n",
    "# Calculate improvements\n",
    "fusion_vs_tabular = (results['fusion']['pr_auc'] - results['tabular_only']['pr_auc']) / results['tabular_only']['pr_auc'] * 100\n",
    "fusion_vs_embeddings = (results['fusion']['pr_auc'] - results['embeddings_only']['pr_auc']) / results['embeddings_only']['pr_auc'] * 100\n",
    "\n",
    "print(f\"\\n{'-'*70}\")\n",
    "print(f\"FUSION IMPROVEMENT:\")\n",
    "print(f\"  vs Tabular:    {fusion_vs_tabular:+.1f}%\")\n",
    "print(f\"  vs Embeddings: {fusion_vs_embeddings:+.1f}%\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Save results\n",
    "with open('e9_fusion_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"\\n✓ Results saved to e9_fusion_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison bar chart\n",
    "sns.set_style('whitegrid')\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "models = ['Tabular\\nOnly', 'Embeddings\\nOnly', 'Fusion']\n",
    "metrics_names = ['PR-AUC', 'ROC-AUC', 'F1']\n",
    "colors = ['#3498db', '#e74c3c', '#2ecc71']\n",
    "\n",
    "for idx, metric_key in enumerate(['pr_auc', 'roc_auc', 'f1']):\n",
    "    values = [\n",
    "        results['tabular_only'][metric_key],\n",
    "        results['embeddings_only'][metric_key],\n",
    "        results['fusion'][metric_key]\n",
    "    ]\n",
    "    \n",
    "    bars = axes[idx].bar(models, values, color=colors)\n",
    "    axes[idx].set_ylabel(metrics_names[idx], fontsize=12)\n",
    "    axes[idx].set_ylim([0, 1])\n",
    "    axes[idx].set_title(f'{metrics_names[idx]} Comparison', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, val in zip(bars, values):\n",
    "        height = bar.get_height()\n",
    "        axes[idx].text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "                      f'{val:.4f}', ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    # Highlight best\n",
    "    best_idx = np.argmax(values)\n",
    "    bars[best_idx].set_edgecolor('gold')\n",
    "    bars[best_idx].set_linewidth(3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('e9_fusion_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Comparison chart saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PR and ROC curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# PR Curves\n",
    "for name, pred, color, label in [\n",
    "    ('tabular', pred_tabular, '#3498db', 'Tabular Only'),\n",
    "    ('embeddings', pred_embeddings, '#e74c3c', 'Embeddings Only'),\n",
    "    ('fusion', pred_fusion, '#2ecc71', 'Fusion')\n",
    "]:\n",
    "    precision, recall, _ = precision_recall_curve(y_test, pred)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    axes[0].plot(recall, precision, color=color, lw=2.5, \n",
    "                label=f'{label} (PR-AUC={pr_auc:.4f})')\n",
    "\n",
    "axes[0].set_xlabel('Recall', fontsize=12)\n",
    "axes[0].set_ylabel('Precision', fontsize=12)\n",
    "axes[0].set_title('Precision-Recall Curves', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(loc='best', fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# ROC Curves\n",
    "for name, pred, color, label in [\n",
    "    ('tabular', pred_tabular, '#3498db', 'Tabular Only'),\n",
    "    ('embeddings', pred_embeddings, '#e74c3c', 'Embeddings Only'),\n",
    "    ('fusion', pred_fusion, '#2ecc71', 'Fusion')\n",
    "]:\n",
    "    fpr, tpr, _ = roc_curve(y_test, pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    axes[1].plot(fpr, tpr, color=color, lw=2.5, \n",
    "                label=f'{label} (ROC-AUC={roc_auc:.4f})')\n",
    "\n",
    "axes[1].plot([0, 1], [0, 1], 'k--', lw=1, alpha=0.3)\n",
    "axes[1].set_xlabel('False Positive Rate', fontsize=12)\n",
    "axes[1].set_ylabel('True Positive Rate', fontsize=12)\n",
    "axes[1].set_title('ROC Curves', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(loc='best', fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('e9_fusion_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ PR/ROC curves saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"E9 WALLET FUSION EXPERIMENT COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nDeliverables:\")\n",
    "print(\"  ✓ e9_tx_embeddings.npy\")\n",
    "print(\"  ✓ e9_addr_embeddings.npy\")\n",
    "print(\"  ✓ e9_fusion_results.json\")\n",
    "print(\"  ✓ e9_fusion_comparison.png\")\n",
    "print(\"  ✓ e9_fusion_curves.png\")\n",
    "\n",
    "print(\"\\nKey Finding:\")\n",
    "if results['fusion']['pr_auc'] > max(results['tabular_only']['pr_auc'], results['embeddings_only']['pr_auc']):\n",
    "    print(\"  ⭐ FUSION WINS: GNN + Tabular > Either alone\")\n",
    "    print(f\"  ⭐ Best PR-AUC: {results['fusion']['pr_auc']:.4f}\")\n",
    "else:\n",
    "    best_model = max(results, key=lambda k: results[k]['pr_auc'])\n",
    "    print(f\"  ⭐ {best_model.upper()} WINS: {results[best_model]['pr_auc']:.4f}\")\n",
    "\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"  1. Download all output files\")\n",
    "print(\"  2. Update COMPARISON_REPORT.md\")\n",
    "print(\"  3. Update README.md\")\n",
    "print(\"  4. Commit to GitHub\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
