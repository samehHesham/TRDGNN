{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß™ E7 ‚Äî HHGTN Ablation Study\n",
    "\n",
    "**Purpose:** Isolate which components hurt TRD-HHGTN performance in E6\n",
    "\n",
    "## Research Questions\n",
    "1. Does heterogeneous architecture hurt vs homogeneous?\n",
    "2. Which edge types contribute/hurt most?\n",
    "3. Are address features harmful?\n",
    "\n",
    "## Experiments\n",
    "- **A1:** tx‚Üítx only (homogeneous-like)\n",
    "- **A2:** addr‚Üîtx only (bipartite)\n",
    "- **A3:** Full E6 (all 4 edge types)\n",
    "- **A4:** Simplified HHGTN (reduced params)\n",
    "\n",
    "## Baseline (E3)\n",
    "- Model: TRD-GraphSAGE\n",
    "- PR-AUC: 0.5582\n",
    "- Features: tx only (AF1-93)\n",
    "\n",
    "## E6 Result (Failed)\n",
    "- Model: TRD-HHGTN\n",
    "- PR-AUC: 0.2806 (-50%)\n",
    "- Features: tx + addr\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== INSTALL DEPENDENCIES ====================\n",
    "!pip install -q torch torch-geometric pandas numpy scikit-learn matplotlib seaborn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== SETUP ====================\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc, f1_score\n",
    "from torch_geometric.nn import SAGEConv, HeteroConv\n",
    "from torch_geometric.data import HeteroData\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Kaggle paths\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Load HeteroData\n",
    "Built in E5 (notebook 02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading HeteroData...\")\n",
    "# Path to your uploaded hetero_graph.pt dataset in Kaggle\n",
    "data = torch.load('/kaggle/input/elliptic-dataset/hetero_graph.pt', weights_only=False)\n",
    "\n",
    "print(\"\\nHeteroData:\")\n",
    "print(data)\n",
    "\n",
    "# Move to device\n",
    "data = data.to(DEVICE)\n",
    "\n",
    "print(f\"\\nData moved to: {DEVICE}\")\n",
    "\n",
    "# Extract masks\n",
    "train_mask = data['transaction'].train_mask\n",
    "val_mask = data['transaction'].val_mask\n",
    "test_mask = data['transaction'].test_mask\n",
    "y = data['transaction'].y\n",
    "\n",
    "print(f\"\\nSplits:\")\n",
    "print(f\"  Train: {train_mask.sum():,}\")\n",
    "print(f\"  Val: {val_mask.sum():,}\")\n",
    "print(f\"  Test: {test_mask.sum():,}\")\n",
    "print(f\"  Fraud rate: {(y[train_mask] == 1).sum().item() / train_mask.sum().item():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Simplified HHGTN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplifiedHHGTN(nn.Module):\n",
    "    \"\"\"Simplified heterogeneous GNN for ablation studies.\"\"\"\n",
    "    \n",
    "    def __init__(self, tx_in_dim, addr_in_dim, hidden_dim, edge_types_to_use, dropout=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.edge_types_to_use = edge_types_to_use\n",
    "        \n",
    "        # Input projections\n",
    "        self.tx_proj = nn.Linear(tx_in_dim, hidden_dim)\n",
    "        self.addr_proj = nn.Linear(addr_in_dim, hidden_dim)\n",
    "        \n",
    "        # Build convolution layers based on edge types\n",
    "        conv_dict = {}\n",
    "        if ('transaction', 'to', 'transaction') in edge_types_to_use:\n",
    "            conv_dict[('transaction', 'to', 'transaction')] = SAGEConv(hidden_dim, hidden_dim)\n",
    "        if ('address', 'to', 'transaction') in edge_types_to_use:\n",
    "            conv_dict[('address', 'to', 'transaction')] = SAGEConv(hidden_dim, hidden_dim)\n",
    "        if ('transaction', 'to', 'address') in edge_types_to_use:\n",
    "            conv_dict[('transaction', 'to', 'address')] = SAGEConv(hidden_dim, hidden_dim)\n",
    "        if ('address', 'to', 'address') in edge_types_to_use:\n",
    "            conv_dict[('address', 'to', 'address')] = SAGEConv(hidden_dim, hidden_dim)\n",
    "        \n",
    "        self.conv1 = HeteroConv(conv_dict, aggr='sum')\n",
    "        self.conv2 = HeteroConv(conv_dict, aggr='sum')\n",
    "        \n",
    "        # Classifier for transactions\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim // 2, 1)\n",
    "        )\n",
    "        \n",
    "        self.dropout = dropout\n",
    "    \n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        # Project inputs\n",
    "        x_dict = {\n",
    "            'transaction': F.relu(self.tx_proj(x_dict['transaction'])),\n",
    "            'address': F.relu(self.addr_proj(x_dict['address']))\n",
    "        }\n",
    "        \n",
    "        # Filter edge_index_dict to only use specified edge types\n",
    "        filtered_edges = {k: v for k, v in edge_index_dict.items() if k in self.edge_types_to_use}\n",
    "        \n",
    "        # Layer 1\n",
    "        x_dict = self.conv1(x_dict, filtered_edges)\n",
    "        x_dict = {key: F.relu(x) for key, x in x_dict.items()}\n",
    "        x_dict = {key: F.dropout(x, p=self.dropout, training=self.training) for key, x in x_dict.items()}\n",
    "        \n",
    "        # Layer 2\n",
    "        x_dict = self.conv2(x_dict, filtered_edges)\n",
    "        x_dict = {key: F.relu(x) for key, x in x_dict.items()}\n",
    "        x_dict = {key: F.dropout(x, p=self.dropout, training=self.training) for key, x in x_dict.items()}\n",
    "        \n",
    "        # Classify transactions\n",
    "        logits = self.classifier(x_dict['transaction'])\n",
    "        \n",
    "        return logits.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data, mask):\n",
    "    \"\"\"Evaluate model on given mask.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        x_dict = {\n",
    "            'transaction': data['transaction'].x,\n",
    "            'address': data['address'].x\n",
    "        }\n",
    "        edge_index_dict = {\n",
    "            k: data[k].edge_index for k in data.edge_types\n",
    "        }\n",
    "        \n",
    "        logits = model(x_dict, edge_index_dict)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        \n",
    "        # Filter to mask\n",
    "        y_true = data['transaction'].y[mask].cpu().numpy()\n",
    "        y_pred = probs[mask].cpu().numpy()\n",
    "        \n",
    "        # Metrics\n",
    "        from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "        \n",
    "        pr_auc = average_precision_score(y_true, y_pred)\n",
    "        roc_auc = roc_auc_score(y_true, y_pred)\n",
    "        \n",
    "        # F1 at best threshold\n",
    "        precision, recall, thresholds = precision_recall_curve(y_true, y_pred)\n",
    "        f1_scores = 2 * precision * recall / (precision + recall + 1e-10)\n",
    "        best_f1 = np.max(f1_scores)\n",
    "        \n",
    "        return {\n",
    "            'pr_auc': pr_auc,\n",
    "            'roc_auc': roc_auc,\n",
    "            'best_f1': best_f1\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ablation_model(model, data, train_mask, val_mask, test_mask, max_epochs=100, patience=15, lr=0.001):\n",
    "    \"\"\"Train model with early stopping.\"\"\"\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([10.0]).to(DEVICE))  # Class imbalance\n",
    "    \n",
    "    best_val_pr_auc = 0\n",
    "    patience_counter = 0\n",
    "    best_epoch = 0\n",
    "    \n",
    "    history = {'train_loss': [], 'val_pr_auc': []}\n",
    "    \n",
    "    for epoch in range(max_epochs):\n",
    "        model.train()\n",
    "        \n",
    "        x_dict = {\n",
    "            'transaction': data['transaction'].x,\n",
    "            'address': data['address'].x\n",
    "        }\n",
    "        edge_index_dict = {\n",
    "            k: data[k].edge_index for k in data.edge_types\n",
    "        }\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        logits = model(x_dict, edge_index_dict)\n",
    "        \n",
    "        # Loss (only on labeled train nodes)\n",
    "        loss = criterion(logits[train_mask], data['transaction'].y[train_mask].float())\n",
    "        \n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Evaluate on val\n",
    "        val_metrics = evaluate_model(model, data, val_mask)\n",
    "        val_pr_auc = val_metrics['pr_auc']\n",
    "        \n",
    "        history['train_loss'].append(loss.item())\n",
    "        history['val_pr_auc'].append(val_pr_auc)\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_pr_auc > best_val_pr_auc:\n",
    "            best_val_pr_auc = val_pr_auc\n",
    "            patience_counter = 0\n",
    "            best_epoch = epoch\n",
    "            # Save best state\n",
    "            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1:3d} | Loss: {loss.item():.4f} | Val PR-AUC: {val_pr_auc:.4f} | Best: {best_val_pr_auc:.4f}\")\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(best_state)\n",
    "    \n",
    "    # Final evaluation\n",
    "    train_metrics = evaluate_model(model, data, train_mask)\n",
    "    val_metrics = evaluate_model(model, data, val_mask)\n",
    "    test_metrics = evaluate_model(model, data, test_mask)\n",
    "    \n",
    "    return {\n",
    "        'train': train_metrics,\n",
    "        'val': val_metrics,\n",
    "        'test': test_metrics,\n",
    "        'best_epoch': best_epoch,\n",
    "        'history': history\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Ablation Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A1: tx‚Üítx only (Homogeneous-like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"A1: tx‚Üítx ONLY (Homogeneous-like)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "edge_types_a1 = [('transaction', 'to', 'transaction')]\n",
    "\n",
    "model_a1 = SimplifiedHHGTN(\n",
    "    tx_in_dim=93,\n",
    "    addr_in_dim=55,\n",
    "    hidden_dim=128,\n",
    "    edge_types_to_use=edge_types_a1,\n",
    "    dropout=0.4\n",
    ").to(DEVICE)\n",
    "\n",
    "print(f\"\\nModel parameters: {sum(p.numel() for p in model_a1.parameters()):,}\")\n",
    "\n",
    "results_a1 = train_ablation_model(\n",
    "    model_a1, data, train_mask, val_mask, test_mask,\n",
    "    max_epochs=100, patience=15, lr=0.001\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"A1 RESULTS\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Test PR-AUC: {results_a1['test']['pr_auc']:.4f}\")\n",
    "print(f\"Test ROC-AUC: {results_a1['test']['roc_auc']:.4f}\")\n",
    "print(f\"Test F1: {results_a1['test']['best_f1']:.4f}\")\n",
    "print(f\"Best epoch: {results_a1['best_epoch']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A2: addr‚Üîtx only (Bipartite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"A2: addr‚Üîtx ONLY (Bipartite)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "edge_types_a2 = [\n",
    "    ('address', 'to', 'transaction'),\n",
    "    ('transaction', 'to', 'address')\n",
    "]\n",
    "\n",
    "model_a2 = SimplifiedHHGTN(\n",
    "    tx_in_dim=93,\n",
    "    addr_in_dim=55,\n",
    "    hidden_dim=128,\n",
    "    edge_types_to_use=edge_types_a2,\n",
    "    dropout=0.4\n",
    ").to(DEVICE)\n",
    "\n",
    "print(f\"\\nModel parameters: {sum(p.numel() for p in model_a2.parameters()):,}\")\n",
    "\n",
    "results_a2 = train_ablation_model(\n",
    "    model_a2, data, train_mask, val_mask, test_mask,\n",
    "    max_epochs=100, patience=15, lr=0.001\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"A2 RESULTS\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Test PR-AUC: {results_a2['test']['pr_auc']:.4f}\")\n",
    "print(f\"Test ROC-AUC: {results_a2['test']['roc_auc']:.4f}\")\n",
    "print(f\"Test F1: {results_a2['test']['best_f1']:.4f}\")\n",
    "print(f\"Best epoch: {results_a2['best_epoch']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A3: All edge types (Full E6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"A3: ALL EDGE TYPES (Full E6)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "edge_types_a3 = [\n",
    "    ('transaction', 'to', 'transaction'),\n",
    "    ('address', 'to', 'transaction'),\n",
    "    ('transaction', 'to', 'address'),\n",
    "    ('address', 'to', 'address')\n",
    "]\n",
    "\n",
    "model_a3 = SimplifiedHHGTN(\n",
    "    tx_in_dim=93,\n",
    "    addr_in_dim=55,\n",
    "    hidden_dim=128,\n",
    "    edge_types_to_use=edge_types_a3,\n",
    "    dropout=0.4\n",
    ").to(DEVICE)\n",
    "\n",
    "print(f\"\\nModel parameters: {sum(p.numel() for p in model_a3.parameters()):,}\")\n",
    "\n",
    "results_a3 = train_ablation_model(\n",
    "    model_a3, data, train_mask, val_mask, test_mask,\n",
    "    max_epochs=100, patience=15, lr=0.001\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"A3 RESULTS\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Test PR-AUC: {results_a3['test']['pr_auc']:.4f}\")\n",
    "print(f\"Test ROC-AUC: {results_a3['test']['roc_auc']:.4f}\")\n",
    "print(f\"Test F1: {results_a3['test']['best_f1']:.4f}\")\n",
    "print(f\"Best epoch: {results_a3['best_epoch']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"E7 ABLATION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "summary_data = {\n",
    "    'Experiment': ['E3 (Baseline)', 'E6 (HHGTN)', 'A1 (tx‚Üítx only)', 'A2 (addr‚Üîtx)', 'A3 (All edges)'],\n",
    "    'Edge Types': ['tx‚Üítx', 'all 4', 'tx‚Üítx', 'addr‚Üîtx', 'all 4'],\n",
    "    'Test PR-AUC': [\n",
    "        0.5582,  # E3 baseline\n",
    "        0.2806,  # E6 result\n",
    "        results_a1['test']['pr_auc'],\n",
    "        results_a2['test']['pr_auc'],\n",
    "        results_a3['test']['pr_auc']\n",
    "    ],\n",
    "    'Test ROC-AUC': [\n",
    "        0.8055,  # E3\n",
    "        0.8250,  # E6\n",
    "        results_a1['test']['roc_auc'],\n",
    "        results_a2['test']['roc_auc'],\n",
    "        results_a3['test']['roc_auc']\n",
    "    ],\n",
    "    'Test F1': [\n",
    "        0.5860,  # E3\n",
    "        0.4927,  # E6\n",
    "        results_a1['test']['best_f1'],\n",
    "        results_a2['test']['best_f1'],\n",
    "        results_a3['test']['best_f1']\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_summary = pd.DataFrame(summary_data)\n",
    "df_summary['Œî PR-AUC from E3'] = df_summary['Test PR-AUC'] - 0.5582\n",
    "\n",
    "print(\"\\n\", df_summary.to_string(index=False))\n",
    "\n",
    "# Save results\n",
    "df_summary.to_csv('e7_ablation_results.csv', index=False)\n",
    "print(\"\\nSaved: e7_ablation_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar chart\n",
    "ax = axes[0]\n",
    "colors = ['green', 'red', 'blue', 'blue', 'blue']\n",
    "bars = ax.bar(df_summary['Experiment'], df_summary['Test PR-AUC'], color=colors, alpha=0.7)\n",
    "ax.axhline(0.5582, color='green', linestyle='--', label='E3 Baseline', linewidth=2)\n",
    "ax.set_ylabel('Test PR-AUC', fontsize=12, fontweight='bold')\n",
    "ax.set_title('E7 Ablation: Test PR-AUC Comparison', fontsize=14, fontweight='bold')\n",
    "ax.set_ylim(0, 0.7)\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "\n",
    "# Delta chart\n",
    "ax = axes[1]\n",
    "delta_colors = ['green' if x >= 0 else 'red' for x in df_summary['Œî PR-AUC from E3']]\n",
    "ax.barh(df_summary['Experiment'], df_summary['Œî PR-AUC from E3'], color=delta_colors, alpha=0.7)\n",
    "ax.axvline(0, color='black', linestyle='-', linewidth=1)\n",
    "ax.set_xlabel('Œî PR-AUC from E3 Baseline', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Performance Delta (Relative to E3)', fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('e7_ablation_comparison.png', dpi=300, bbox_inches='tight')\n",
    "print(\"\\nSaved: e7_ablation_comparison.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Key Findings\n",
    "\n",
    "**Questions Answered:**\n",
    "\n",
    "1. **Does heterogeneous architecture hurt?**\n",
    "   - Compare A1 (tx‚Üítx only in hetero framework) vs E3 (tx‚Üítx in homogeneous)\n",
    "   - If A1 < E3: Yes, heterogeneous framework adds overhead\n",
    "\n",
    "2. **Which edge types hurt most?**\n",
    "   - A1 (tx‚Üítx): Baseline within hetero framework\n",
    "   - A2 (addr‚Üîtx): Tests if bipartite structure helps\n",
    "   - A3 (all): Full E6 configuration\n",
    "\n",
    "3. **Are address features harmful?**\n",
    "   - A2 directly uses address features via bipartite edges\n",
    "   - If A2 << A1: Address features likely noisy/harmful\n",
    "\n",
    "**Expected Insights:**\n",
    "- If A1 ‚âà E3: Hetero framework OK, problem is address features\n",
    "- If A1 < E3: Hetero framework itself adds complexity\n",
    "- If A2 << A1: Bipartite edges (address features) are the culprit\n",
    "- If A3 ‚âà A2: Adding addr‚Üíaddr doesn't help/hurt much"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
