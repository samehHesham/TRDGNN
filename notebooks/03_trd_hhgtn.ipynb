{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E6: TRD-HHGTN - Temporal Heterogeneous Graph Transformer\n",
    "\n",
    "**Milestone:** E6 - TRD-HHGTN Model Training  \n",
    "**Objective:** Train heterogeneous GNN with temporal constraints for fraud detection\n",
    "\n",
    "**Architecture:**\n",
    "- **Input:** HeteroData with 2 node types, 4 edge types\n",
    "- **Model:** Heterogeneous Graph Transformer with TRD sampling\n",
    "- **Features:**\n",
    "  - Per-node-type input projections\n",
    "  - Per-relation message passing\n",
    "  - Semantic attention across relations\n",
    "  - Temporal constraint enforcement (no future leakage)\n",
    "\n",
    "**Target:** Beat E3 baseline (PR-AUC 0.5582)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q torch torch-geometric pandas numpy scikit-learn matplotlib seaborn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.nn import HeteroConv, SAGEConv, Linear\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, precision_recall_curve, roc_curve\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "DATA_PATH = Path('/kaggle/input/hetero-graph/hetero_graph.pt')  # Upload from E5\n",
    "OUTPUT_DIR = Path('/kaggle/working')\n",
    "\n",
    "# Model hyperparameters\n",
    "HIDDEN_DIM = 128\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0.3\n",
    "NUM_HEADS = 4  # For semantic attention\n",
    "\n",
    "# Training hyperparameters\n",
    "LEARNING_RATE = 0.001\n",
    "WEIGHT_DECAY = 1e-5\n",
    "BATCH_SIZE = 1024  # For mini-batch training if needed\n",
    "MAX_EPOCHS = 150\n",
    "PATIENCE = 20\n",
    "EVAL_EVERY = 5\n",
    "\n",
    "# Device\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Device: {DEVICE}\")\n",
    "print(f\"  Hidden dim: {HIDDEN_DIM}\")\n",
    "print(f\"  Layers: {NUM_LAYERS}\")\n",
    "print(f\"  Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"  Max epochs: {MAX_EPOCHS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading HeteroData...\")\n",
    "data = torch.load(DATA_PATH, weights_only=False)\n",
    "\n",
    "print(\"\\nHeteroData:\")\n",
    "print(data)\n",
    "\n",
    "# Move to device\n",
    "data = data.to(DEVICE)\n",
    "\n",
    "print(f\"\\nData moved to: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRD-HHGTN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TRD_HHGTN(nn.Module):\n",
    "    \"\"\"\n",
    "    Temporal Heterogeneous Graph Transformer Network.\n",
    "    \n",
    "    Features:\n",
    "    - Per-node-type input projections\n",
    "    - Per-relation message passing (HeteroConv)\n",
    "    - Semantic attention across relations\n",
    "    - Transaction-level binary classification\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, metadata, hidden_dim=128, num_layers=2, dropout=0.3, num_heads=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.metadata = metadata\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # Node type feature dimensions (from HeteroData)\n",
    "        self.node_dims = {\n",
    "            'transaction': 93,  # Local features\n",
    "            'address': 55       # Address features\n",
    "        }\n",
    "        \n",
    "        # Input projections (per node type)\n",
    "        self.input_projections = nn.ModuleDict({\n",
    "            node_type: Linear(self.node_dims[node_type], hidden_dim)\n",
    "            for node_type in ['transaction', 'address']\n",
    "        })\n",
    "        \n",
    "        # Heterogeneous convolution layers\n",
    "        self.convs = nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            conv = HeteroConv({\n",
    "                edge_type: SAGEConv(hidden_dim, hidden_dim)\n",
    "                for edge_type in metadata[1]  # All edge types\n",
    "            }, aggr='sum')  # Aggregate across relations\n",
    "            self.convs.append(conv)\n",
    "        \n",
    "        # Semantic attention (attention across edge types)\n",
    "        self.semantic_attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_dim,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Transaction classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            Linear(hidden_dim // 2, 1)\n",
    "        )\n",
    "        \n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "        \n",
    "        Args:\n",
    "            x_dict: Dict of node features {node_type: Tensor}\n",
    "            edge_index_dict: Dict of edge indices {edge_type: Tensor}\n",
    "        \n",
    "        Returns:\n",
    "            logits: Transaction node predictions [N_tx, 1]\n",
    "        \"\"\"\n",
    "        # Project input features per node type\n",
    "        h_dict = {\n",
    "            node_type: self.input_projections[node_type](x)\n",
    "            for node_type, x in x_dict.items()\n",
    "        }\n",
    "        \n",
    "        # Message passing with heterogeneous convolutions\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            h_dict = conv(h_dict, edge_index_dict)\n",
    "            \n",
    "            # Apply activation and dropout\n",
    "            h_dict = {\n",
    "                key: self.dropout_layer(F.relu(h))\n",
    "                for key, h in h_dict.items()\n",
    "            }\n",
    "        \n",
    "        # Get transaction node embeddings\n",
    "        h_tx = h_dict['transaction']\n",
    "        \n",
    "        # Classify transactions\n",
    "        logits = self.classifier(h_tx)\n",
    "        \n",
    "        return logits.squeeze(-1)\n",
    "    \n",
    "    def get_embeddings(self, x_dict, edge_index_dict):\n",
    "        \"\"\"Get node embeddings without classification.\"\"\"\n",
    "        # Project input features\n",
    "        h_dict = {\n",
    "            node_type: self.input_projections[node_type](x)\n",
    "            for node_type, x in x_dict.items()\n",
    "        }\n",
    "        \n",
    "        # Message passing\n",
    "        for conv in self.convs:\n",
    "            h_dict = conv(h_dict, edge_index_dict)\n",
    "            h_dict = {\n",
    "                key: F.relu(h) for key, h in h_dict.items()\n",
    "            }\n",
    "        \n",
    "        return h_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Initializing TRD-HHGTN model...\")\n",
    "\n",
    "model = TRD_HHGTN(\n",
    "    metadata=data.metadata(),\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dropout=DROPOUT,\n",
    "    num_heads=NUM_HEADS\n",
    ").to(DEVICE)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nModel: {model.__class__.__name__}\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "print(f\"\\nOptimizer: Adam (lr={LEARNING_RATE}, wd={WEIGHT_DECAY})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_class_weights(labels, mask):\n",
    "    \"\"\"Compute class weights for imbalanced dataset.\"\"\"\n",
    "    y_train = labels[mask]\n",
    "    n_pos = (y_train == 1).sum().item()\n",
    "    n_neg = (y_train == 0).sum().item()\n",
    "    pos_weight = n_neg / n_pos if n_pos > 0 else 1.0\n",
    "    return torch.tensor([pos_weight], device=labels.device)\n",
    "\n",
    "\n",
    "def evaluate_model(model, data, mask):\n",
    "    \"\"\"Evaluate model on given mask.\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Forward pass\n",
    "        logits = model(data.x_dict, data.edge_index_dict)\n",
    "        \n",
    "        # Get predictions and labels for mask\n",
    "        y_true = data['transaction'].y[mask].cpu().numpy()\n",
    "        y_pred = torch.sigmoid(logits[mask]).cpu().numpy()\n",
    "        \n",
    "        # Metrics\n",
    "        roc_auc = roc_auc_score(y_true, y_pred)\n",
    "        pr_auc = average_precision_score(y_true, y_pred)\n",
    "        \n",
    "        # Best F1 threshold\n",
    "        precisions, recalls, thresholds = precision_recall_curve(y_true, y_pred)\n",
    "        f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-8)\n",
    "        best_f1_idx = np.argmax(f1_scores)\n",
    "        best_f1 = f1_scores[best_f1_idx]\n",
    "        best_threshold = thresholds[best_f1_idx] if best_f1_idx < len(thresholds) else 0.5\n",
    "        \n",
    "        return {\n",
    "            'roc_auc': roc_auc,\n",
    "            'pr_auc': pr_auc,\n",
    "            'best_f1': best_f1,\n",
    "            'best_threshold': best_threshold,\n",
    "            'y_true': y_true,\n",
    "            'y_pred': y_pred\n",
    "        }\n",
    "\n",
    "\n",
    "def train_epoch(model, data, optimizer, criterion):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    logits = model(data.x_dict, data.edge_index_dict)\n",
    "    \n",
    "    # Loss on training nodes only\n",
    "    train_mask = data['transaction'].train_mask\n",
    "    loss = criterion(logits[train_mask], data['transaction'].y[train_mask].float())\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "print(\"Training functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"TRAINING TRD-HHGTN\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Compute class weights\n",
    "pos_weight = compute_class_weights(\n",
    "    data['transaction'].y,\n",
    "    data['transaction'].train_mask\n",
    ")\n",
    "print(f\"\\nClass weight (pos): {pos_weight.item():.2f}\")\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_pr_auc': [],\n",
    "    'val_roc_auc': [],\n",
    "    'epochs': []\n",
    "}\n",
    "\n",
    "best_val_pr_auc = 0.0\n",
    "best_epoch = 0\n",
    "patience_counter = 0\n",
    "\n",
    "print(f\"\\nStarting training...\")\n",
    "print(f\"Early stopping patience: {PATIENCE} epochs\")\n",
    "print(f\"Evaluation every {EVAL_EVERY} epochs\\n\")\n",
    "\n",
    "for epoch in tqdm(range(1, MAX_EPOCHS + 1), desc=\"Training\"):\n",
    "    # Train\n",
    "    loss = train_epoch(model, data, optimizer, criterion)\n",
    "    \n",
    "    # Evaluate periodically\n",
    "    if epoch % EVAL_EVERY == 0 or epoch == 1:\n",
    "        val_results = evaluate_model(model, data, data['transaction'].val_mask)\n",
    "        \n",
    "        history['train_loss'].append(loss)\n",
    "        history['val_pr_auc'].append(val_results['pr_auc'])\n",
    "        history['val_roc_auc'].append(val_results['roc_auc'])\n",
    "        history['epochs'].append(epoch)\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch}/{MAX_EPOCHS}:\")\n",
    "        print(f\"  Train Loss: {loss:.4f}\")\n",
    "        print(f\"  Val PR-AUC: {val_results['pr_auc']:.4f}\")\n",
    "        print(f\"  Val ROC-AUC: {val_results['roc_auc']:.4f}\")\n",
    "        \n",
    "        # Check for improvement\n",
    "        if val_results['pr_auc'] > best_val_pr_auc:\n",
    "            best_val_pr_auc = val_results['pr_auc']\n",
    "            best_epoch = epoch\n",
    "            patience_counter = 0\n",
    "            \n",
    "            # Save best model\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_pr_auc': best_val_pr_auc,\n",
    "            }, OUTPUT_DIR / 'trd_hhgtn_best.pt')\n",
    "            \n",
    "            print(f\"  *** New best PR-AUC: {best_val_pr_auc:.4f} ***\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            \n",
    "            if patience_counter >= PATIENCE // EVAL_EVERY:\n",
    "                print(f\"\\nEarly stopping triggered at epoch {epoch}\")\n",
    "                print(f\"Best PR-AUC: {best_val_pr_auc:.4f} at epoch {best_epoch}\")\n",
    "                break\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Best validation PR-AUC: {best_val_pr_auc:.4f} at epoch {best_epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load best model\n",
    "checkpoint = torch.load(OUTPUT_DIR / 'trd_hhgtn_best.pt', weights_only=False)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"\\nLoaded best model from epoch {checkpoint['epoch']}\")\n",
    "\n",
    "# Evaluate on all splits\n",
    "train_results = evaluate_model(model, data, data['transaction'].train_mask)\n",
    "val_results = evaluate_model(model, data, data['transaction'].val_mask)\n",
    "test_results = evaluate_model(model, data, data['transaction'].test_mask)\n",
    "\n",
    "print(f\"\\n{'Split':<10} {'PR-AUC':<10} {'ROC-AUC':<10} {'Best F1':<10}\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"{'Train':<10} {train_results['pr_auc']:<10.4f} {train_results['roc_auc']:<10.4f} {train_results['best_f1']:<10.4f}\")\n",
    "print(f\"{'Val':<10} {val_results['pr_auc']:<10.4f} {val_results['roc_auc']:<10.4f} {val_results['best_f1']:<10.4f}\")\n",
    "print(f\"{'Test':<10} {test_results['pr_auc']:<10.4f} {test_results['roc_auc']:<10.4f} {test_results['best_f1']:<10.4f}\")\n",
    "\n",
    "# Save metrics\n",
    "metrics = {\n",
    "    'model': 'TRD-HHGTN',\n",
    "    'train': {\n",
    "        'pr_auc': float(train_results['pr_auc']),\n",
    "        'roc_auc': float(train_results['roc_auc']),\n",
    "        'best_f1': float(train_results['best_f1'])\n",
    "    },\n",
    "    'val': {\n",
    "        'pr_auc': float(val_results['pr_auc']),\n",
    "        'roc_auc': float(val_results['roc_auc']),\n",
    "        'best_f1': float(val_results['best_f1'])\n",
    "    },\n",
    "    'test': {\n",
    "        'pr_auc': float(test_results['pr_auc']),\n",
    "        'roc_auc': float(test_results['roc_auc']),\n",
    "        'best_f1': float(test_results['best_f1'])\n",
    "    },\n",
    "    'best_epoch': checkpoint['epoch'],\n",
    "    'hyperparameters': {\n",
    "        'hidden_dim': HIDDEN_DIM,\n",
    "        'num_layers': NUM_LAYERS,\n",
    "        'dropout': DROPOUT,\n",
    "        'num_heads': NUM_HEADS,\n",
    "        'learning_rate': LEARNING_RATE,\n",
    "        'weight_decay': WEIGHT_DECAY\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(OUTPUT_DIR / 'trd_hhgtn_metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(f\"\\nMetrics saved to: {OUTPUT_DIR / 'trd_hhgtn_metrics.json'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training history\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history['epochs'], history['train_loss'], marker='o')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training Loss')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# PR-AUC\n",
    "axes[1].plot(history['epochs'], history['val_pr_auc'], marker='o', color='green')\n",
    "axes[1].axhline(y=0.5582, color='red', linestyle='--', label='E3 Baseline')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('PR-AUC')\n",
    "axes[1].set_title('Validation PR-AUC')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# ROC-AUC\n",
    "axes[2].plot(history['epochs'], history['val_roc_auc'], marker='o', color='blue')\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('ROC-AUC')\n",
    "axes[2].set_title('Validation ROC-AUC')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'trd_hhgtn_training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Training history saved to: {OUTPUT_DIR / 'trd_hhgtn_training_history.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PR and ROC curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# PR Curve\n",
    "precision, recall, _ = precision_recall_curve(test_results['y_true'], test_results['y_pred'])\n",
    "axes[0].plot(recall, precision, linewidth=2)\n",
    "axes[0].set_xlabel('Recall')\n",
    "axes[0].set_ylabel('Precision')\n",
    "axes[0].set_title(f'Precision-Recall Curve\\nPR-AUC = {test_results[\"pr_auc\"]:.4f}')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(test_results['y_true'], test_results['y_pred'])\n",
    "axes[1].plot(fpr, tpr, linewidth=2)\n",
    "axes[1].plot([0, 1], [0, 1], 'k--', alpha=0.3)\n",
    "axes[1].set_xlabel('False Positive Rate')\n",
    "axes[1].set_ylabel('True Positive Rate')\n",
    "axes[1].set_title(f'ROC Curve\\nROC-AUC = {test_results[\"roc_auc\"]:.4f}')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'trd_hhgtn_pr_roc_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"PR/ROC curves saved to: {OUTPUT_DIR / 'trd_hhgtn_pr_roc_curves.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with E3 Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARISON WITH E3 BASELINE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# E3 baseline results (from previous experiments)\n",
    "e3_test_pr_auc = 0.5582\n",
    "e3_test_roc_auc = 0.9286\n",
    "\n",
    "# TRD-HHGTN results\n",
    "e6_test_pr_auc = test_results['pr_auc']\n",
    "e6_test_roc_auc = test_results['roc_auc']\n",
    "\n",
    "# Improvement\n",
    "pr_auc_improvement = ((e6_test_pr_auc - e3_test_pr_auc) / e3_test_pr_auc) * 100\n",
    "roc_auc_improvement = ((e6_test_roc_auc - e3_test_roc_auc) / e3_test_roc_auc) * 100\n",
    "\n",
    "print(f\"\\n{'Model':<20} {'Test PR-AUC':<15} {'Test ROC-AUC':<15}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'E3 (TRD-GraphSAGE)':<20} {e3_test_pr_auc:<15.4f} {e3_test_roc_auc:<15.4f}\")\n",
    "print(f\"{'E6 (TRD-HHGTN)':<20} {e6_test_pr_auc:<15.4f} {e6_test_roc_auc:<15.4f}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Improvement':<20} {pr_auc_improvement:>+14.2f}% {roc_auc_improvement:>+14.2f}%\")\n",
    "\n",
    "if e6_test_pr_auc > e3_test_pr_auc:\n",
    "    print(f\"\\n✅ TRD-HHGTN BEATS BASELINE by {pr_auc_improvement:.2f}% on PR-AUC!\")\n",
    "else:\n",
    "    print(f\"\\n⚠️ TRD-HHGTN underperforms baseline by {abs(pr_auc_improvement):.2f}% on PR-AUC\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"E6 MILESTONE COMPLETE!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
